# Python-Crawler

This is a learning document about Python web crawlers, which includes two parts: learning examples and practical
operations. This project will involve web crawlers, big data, and artificial intelligence. Please regulate your own
operations and do not maliciously attack other people's web pages. We hope everyone can learn something from it.

## Directory Catalog

```
Python-Crawler:
--- catalog or file
	|--bin       -- start.py
	|--conf      -- settings.py
	|--core      -- code.py
	|--data      -- db/cache: data/sql
	|--docs      -- pdf,word,md
	|--env       -- environment.env
	|--example   -- example: other projects examples
	|--lib       -- common.py
	|--log       -- log.log
	|--model     -- entity.py
	|--out       -- output: something
	|--setup     -- setup: Scripts for installation, deployment, and packaging
	|--test      -- test.py
	|--quirements.txt
	|--README.md
```

## Contents

* [Quick start](#quick-start)

## Quick start

Start a Python-Crawler with a command

```bash
pip install -r requirements.txt
```